#import "./template.typ": *
#import "./theme.typ": *
= Implementation <Implementation>

As mentioned during the in @Introduction we implemented both the `Rew` and the `Subterm` algorithms in Lean 4 and compared the resulting constraints.

Our implementation aligns closely with the algorithms seen in @rewalgo and @subterm. To keep track of what side of a rewrite-relation-proof needs to unify we carry along variable for the direction mentioned in @PaperAlgo that we call `l2r`. This variable provides the context of which subterm of a rewrite theorem $rho : r space l space r$ must unify inside the unification function. The choice between $(<-)$ and $(->)$ is directed by the desired relation $r$ mentioned in @subterm. We also had to implement more logic for deeply nested rewrites of a function $f$ at the beginning of an application sequence. While the rewriting in Coq can usually recursively rewrite all occurrences of the respective left-hand-side or right-hand-side of a rewrite theorem, it is not able to do that on functions.

In order to rewrite the function of an application in Coq we have to define the according subrelation, pointwise relation, and relation constraints. Consider a rewrite theorem $rho : r space f space g$. $f$ and $g$ are of type $alpha -> mono("Prop") -> beta -> mono("Prop")$. Rewriting $f$ to $g$ in a term $f space a space (a = a) space b$ where $a$ is of type $alpha$ and $b$ of type $beta$ in the Coq algorithm provides a proof e.g. with $(<-)$ as the desired relation for $f space a space (a = a) space b <- g space a space (a = a) space b$. In our `Subterm` algorithm we would enter the path starting at line 8 in @subterm and produce the according proof. However, when changing the term to $f space a space (f space a space (a = a) space b) space b$ Coq currently only provides a proof for $f space a space (f space a space (a = a) space b) space b <- g space a space (f space a space (a = a) space b) space b$. We can see that only the outer $f$ is rewritten by Coq's implementation. In the special case where $r$ is equality Coq applies the leibniz-equality algorithm and replaces both occurances of $f$.

This inconsistency in the Coq implementation is a crucial difference to the `Rew` algorithm which would rewrite all occurrences of $f$ even when the relation is not equality. This is where we made some further changes to our by Coq-inspired `Subterm` algorithm levering transitivity of implications (or open relations) as mentioned in @updatedalgo. As transitivity cannot be shown for possibly non-transitive rewrite relation $r$ we must perform a subrelation inference to the desired relation passed as argument to `Subterm` immediately. This ensures that both terms are proofs over an identical relation which is required by the `Transitive` typeclass that we will need. When we operate on `Prop` directly the inferred relation is either $(<-)$ or $(->)$ and therefore already transitive. In the other case we are in a nested call of the application case and thus work with a metavariable of type $mono("relation " tau)$ that we can force to be transitive during the proof search. This does not change our invariants as we always treat relations general enough so that it does not matter whether we work with metavariables of type $mono("relation " tau)$ or given instances of that type.

Once we inferred the relation to the desired transitive relation $r$, we can perform another rewrite on the updated term $u$. In the recursive call with $u$ the first occurrence was already replaced to $g$ and we follow the procedure for application arguments starting at line 13 in @subterm. This would invoke yet another recursive invocation where $f$ is again the function rewrite. This is how we can rewrite a term, for instance $f space a space (f space a space (f space a space (mono("True")) space b) space b) space b$, directly to $g space a space (g space a space (g space a space (mono("True")) space b) space b) space b$ and thus truly generate the same rewrites that `Rew` produces. The downside of this approach is that with many occurrences of $f$ we generate almost as many `Subrelation` metavariables as the `Rew` algorithm would for this example. The `Transitive` instances however are trivial to solve and can even be closed during the constraint generation as all implications are transitive.

It is a common use case to perform rewrites using existing theorems such as addition commutativity or `Nat.add_comm` ($forall n space m : NN, n + m = m + n$) or `Nat.right_distrib` ($forall n space m space k : NN, (n+m) dot k = n dot k + m dot k$). Both of those theorems are defined with all-quantifiers. During the execution of the algorithm for constraint generation we are looking for unifications of the term $n + m$ for $rho := mono("Nat.add_comm")$ assuming a left-to-right rewrite. That means we have to go inside the $forall$-binder every time. As this information does not change during the execution we wrapped the algorithm in a reader monad containing all relevant information about the theorem in the context. This is the carrier relation $=$, the left-hand-side of $rho$, the right-hand-side of $rho$, the proof $rho$, and the possible metavariables for unused binder variables. Those unused binder variables eventually become goals for the user to solve and will not be affected by the proof search.

The paper for generalised rewriting in type theory @sozeau:inria-00628904 that inspired the Coq implementation and the official Coq library for morphisms @coqmorphism mentions many theorems that drastically simplify the constraints generated by the `Rew` or `Subterm` constraint generation algorithms. Both sources also rely on typeclass search. This has two advantages in Coq. Firstly, the by Haskell inspired typeclass system @casteran:hal-00702455 keeps track of all instances defined for a typeclass and allows access to those when resolving a typeclass. This is a convenient approach for users to create new instances that directly influence the proof search.

For instance one example mentioned in the paper @casteran:hal-00702455 defines a primitive version of sets where a set is just `Type` and `eqset` the equivalence of sets, is thus a relation over set `SET` $->$ `SET` $->$ `Prop` and union is a function `Set` $->$ `Set` $->$ `Set`. If we want to leverage some theorems about sets for rewriting we generate proper constraints as part of the proof skeleton generation. By defining the typeclass instance $mono("instance union_proper" : mono("Proper") space (mono("eqset") ==> mono("eqset") ==> mono("eqset")) space mono("union"))$ anywhere in the code we assure that this instance is leveraged when a fitting `Proper` constraint is being solved.

The other reason Coq uses its typecalass search for the algorithm is because it can be extended with arbitrary theorems and tactics. This is crucial as the type class instances mentioned in the paper are not sufficient for solving the generated problems. This is why Coq's documentation @coqmorphism also contains a few tactics that apply theorems in a very specific order to take a shortcut in the proof search. For instance the tactic`reflexive_proxy_tac` checks if there is a free existential variable (metavariable in Coq) of type relation and if so assigns any reflexive relation (provided by the `find_rewrite_relation` tactic) followed by a theorem that transforms a `ProperProxy` term into a `ReflexiveProxy` and eventually a `Reflexive` class.

Although the typeclass search in Lean is very efficient and tailored to ad-hoc polymorphism @selsam2020tabledtypeclassresolution it does not currently support arbitrary extension by custom tactics and theorems. This is also not a planned feature because it would disrupt the performance predictability. It would make it challenging to keep an overview of what tactics or theorems from possibly nested imports slow down a typeclass resolution. For this reason we decided to develop our own extensible proof search and translated most typeclass instances and tactics from Coqs morphism library @coqmorphism to Lean theorems and Meta-tactics.

While we used aesop @aesop initially in combination with the `Rew` algorithm to solve simple goals, we combined the optimisations in the constraint generation in `Subterm` with a proof search that focuses on backtracking beyond the currently active goal. We store all registered theorems inside a discrimination tree @discrtree which can efficiently store arbitrary values (theorems in our case) using a Lean expression as key. This allowed us to find theorems that can transform a given goal. In fact Lean uses this data structure for its typeclass resolution as well @aesop.

With goals stored efficiently we solve the syntactic holes in the rewrite proof skeleton by a depth-first proof search where we apply the first theorem that matches the current goal and directly move forward with the updated goal. Only when we cannot apply any more theorems we backtrack. When a goal gets closed, we proceed to the next goal. It may also happen that already solved goals are unsolved again because metavariables can be shared.
